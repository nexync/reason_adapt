default:
  naive: False
  tune_model_path: "../models/llama3-8b-r1/"
  base_model_path: "../models/llama3-8b/"
  checkpoint_path: "./checkpoints/attn_rank_16/alpha_8/"
  adapter_path: "./checkpoints/adapter.pt"
  lora_ratio: 1.0
  reason_ratio: 1.0
  tokenizer_path: "../models/llama3-8b-r1/"
  dataset_path: "./data/sara/"
  use_cuda: True
  batch_size: 4
  save_dir: "./out/attn_r16_a8/"
